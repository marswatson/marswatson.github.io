<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Siyuan&#39;s Blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-05-26T18:32:34.686Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Siyuan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Deep Learning: Neural Style Transfer</title>
    <link href="http://yoursite.com/2017/05/26/Deep-Learning-Neural-Style-Transfer/"/>
    <id>http://yoursite.com/2017/05/26/Deep-Learning-Neural-Style-Transfer/</id>
    <published>2017-05-26T17:27:45.000Z</published>
    <updated>2017-05-26T18:32:34.686Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Deep-Learning-Neural-Style-Transfer"><a href="#Deep-Learning-Neural-Style-Transfer" class="headerlink" title="Deep Learning: Neural Style Transfer"></a>Deep Learning: Neural Style Transfer</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the art field, especially painting, human always tried make the impressive art work. In our daily life, we take picture every day, but some of them may not attractive. So we can use this deep learning knowledge to make the machine can learn the famous painting feature and style, then combine the content with our own image which may produce a new fashion image. </p>
<p>This neural style transfer paper \cite{c1} first been released in 2015. Since the release of the Neural Style paper, there have been a number of applications that used it to apply stylistic transfers from one image to another. And the most famous one is Prisma. The innovation of this project is based on it. So in this project I transfered image to art style by using the VGG neural networks which we have discussion in the class.</p>
<p><img src="../images/neural-style-transfer/prisma.jpg" alt="prisma"></p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>This neural style transfer used neural network implementation to learn the art paintings, and then combined the content information to create new image.</p>
<h3 id="VGG-Neural-Network"><a href="#VGG-Neural-Network" class="headerlink" title="VGG Neural Network"></a>VGG Neural Network</h3><p>Before we want to do our project, we must learn what is the neural network. Because in this project, we used this VGG neural network.<br>VGG neural network is one of famous convolution neural network because of its good performance compare to other neural network structure. The convolution neural network can be seem as two part. The first is convolution layer part, the second is fully connected layer part. You can see vgg structure from Figure below.</p>
<p><img src="../images/neural-style-transfer/vgg.png" alt="VGG network"></p>
<p>When we applied image to neural network, we can seem that the convolution layer will produce the feature of image. And the fully connected layer can be seem as the classifier with input the feature vector. Because in this project, our goal is not to do image classification, we only want to use the feature vector of image. So we can ignore the fully connect layer part. </p>
<p>In this project, we used the VGG19 structure, which totally contain the 16 convolution layers, 5 pooling layers, 3 fully connected layers. We will use the pre-trained VGG network to do this project.</p>
<h3 id="Create-Image"><a href="#Create-Image" class="headerlink" title="Create Image"></a>Create Image</h3><p>The main idea of create image are minimize the loss function of content information and style information.</p>
<h4 id="Content-Image-Transfer"><a href="#Content-Image-Transfer" class="headerlink" title="Content Image Transfer"></a>Content Image Transfer</h4><p>Suppose our content image $x$ passed the neural network. The response of every convolution layer $l$ will get the feature map $F^l$. Then we need to find new image $p$ which also pass the same neural network, in the same convolution layer $l$ will get new feature map $P^l$. The image $p$ first was generate as white noise image. Then we apply gradient descent on this white noise image to find another image that matches the feature response of the original image. So we can defined original image and generated image as $x$ and $p$, then find its image response at layer $l$, which is $F^l$ and $P^l$. And defined the squared-error loss between this two feature map.</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Loss_{content} = \frac{1}{2}(F^l-P^l)^2" style="border:none;"></p>
<h4 id="Style-Image-Transfer"><a href="#Style-Image-Transfer" class="headerlink" title="Style Image Transfer"></a>Style Image Transfer</h4><p>In this step only want to get the style image style representation. And in the convolution layer, suppose its output channel number is $N$, then the input image in this convolution layer $l$ will have N filter feature response. And this style representation can be compute the correlations between the different filter response. And this feature correlation are given by the Gram Matrix $G<em>l \in R^{(N^l \times N^l)}$, and $G</em>{ij}$ is the inner product between the vectorised feature map.</p>
<p><img src="../images/neural-style-transfer/1-style.jpg" alt="1-style"><br><img src="../images/neural-style-transfer/IMG1.jpg" alt="IMG1"><br>neural style transfer example</p>
<p><img src="../images/neural-style-transfer/test500.jpg" alt="test500"><br>500 iteration</p>
<p><img src="../images/neural-style-transfer/test1000.jpg" alt="test1000"><br>1000 iteration</p>
<p><img src="../images/neural-style-transfer/test1500.jpg" alt="test1500"><br>1500 iteration</p>
<p><img src="../images/neural-style-transfer/test2000.jpg" alt="test2000"><br>2000 iteration</p>
<p>To generate texture match the style image, we use same method as create content image. We also use gradient descent from a white noise image to find another image that match style representation of original style image. This is done by minimising the mean-squared distance between the entries of the Gram matrix $G_l$ from original image and the Gram matrix $A_l$ of image to be generated. Then give the weight to each layer output error, and sum them all to get the total loss of style.</p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large E_l = \frac{1}{N^2_l}(G_l - A_l)^2" style="border:none;"></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Loss_{style} = \sum_{l=0}^L w_lE_l" style="border:none;"></p>
<p>After above steps, we can combine the content loss and style loss to get total loss. $\alpha$ and $\beta$ is the weight parameter for content loss and style loss. </p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large Loss_{total} = \alpha Loss_{content} + \beta Loss_{Style}" style="border:none;"></p>
<h2 id="Experiment-Result"><a href="#Experiment-Result" class="headerlink" title="Experiment Result"></a>Experiment Result</h2><p>I implement this neural style transfer image as above illustrated by tensorflow. </p>
<p>Here is the some example of my experiment. I set the $\frac{\alpha}{ \beta}$ to 0.01, and use average pooling instead of max pooling in the VGG network. Because in the paper\cite{c1} the author find average pooling improves the gradient flow and one obtains slightly more appealing result. The content layer I use is $conv4_1$. For the style layer, I use all five convolution layer and set the equal weight to $E_l$.</p>
<p>Figure\ref{fig:input1} is the input image for our program, one is the style image and one is content image. Figure\ref{fig:output1} is the neural transfered image. From the above results, we can see that with increase of iterations, the neural style image have better quality. </p>
<p>Figure \ref{style 2} \ref{img2} \ref{Output2} is another result of my project. And this output image is more beautiful compare to the previous example.</p>
<p><img src="../images/neural-style-transfer/4-style.jpg" alt="4-style"><br>Style Image</p>
<p><img src="../images/neural-style-transfer/IMG2.jpg" alt="IMG2"><br>Content Image New York</p>
<p><img src="../images/neural-style-transfer/test1000-2.jpg" alt="test1000-2"><br>Output image</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this project, I tried to implement the neural style transfer algorithm. This let me have better understanding on the neural network. Besides, I also learned the technology behind this cool work. Although this neural transfer algorithm heard likes difficult, but the principle behind it is not too hard.</p>
<p>There are also many future work we can do. Such when we want to transfer an image, we can segment the image to different part, and use different style to different part. </p>
<p>There are also some drawback of this project. Every time when we want to generate new image, it takes lots of time to generate one. So if we want to use this algorithm in our life, we must consider this properties.</p>
<h3 id="Stuff-used-to-make-this"><a href="#Stuff-used-to-make-this" class="headerlink" title="Stuff used to make this:"></a>Stuff used to make this:</h3><ul>
<li>[paper1] L. A. Gatys, A. S. Ecker, and M. Bethge. A neural algorithm<br>of artistic style. arXiv preprint arXiv:1508.06576, 2015.</li>
<li>[Gram Matrix] (<a href="https://en.wikipedia.org/wiki/Gramian_matrix" target="_blank" rel="external">https://en.wikipedia.org/wiki/Gramian_matrix</a>)</li>
<li>[Github code] (<a href="https://github.com/dankogai/js-deflate" target="_blank" rel="external">https://github.com/dankogai/js-deflate</a>)</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Deep-Learning-Neural-Style-Transfer&quot;&gt;&lt;a href=&quot;#Deep-Learning-Neural-Style-Transfer&quot; class=&quot;headerlink&quot; title=&quot;Deep Learning: Neural 
    
    </summary>
    
    
      <category term="-tensorflow -deeplearning" scheme="http://yoursite.com/tags/tensorflow-deeplearning/"/>
    
  </entry>
  
  <entry>
    <title>Some basic linux operation</title>
    <link href="http://yoursite.com/2017/04/25/Some-basic-linux-operation/"/>
    <id>http://yoursite.com/2017/04/25/Some-basic-linux-operation/</id>
    <published>2017-04-25T13:39:22.000Z</published>
    <updated>2017-04-25T13:48:23.077Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Some-basic-Linux-operation"><a href="#Some-basic-Linux-operation" class="headerlink" title="Some basic Linux operation"></a>Some basic Linux operation</h1><p>Find file</p>
<ul>
<li>find . -name “<em>spark</em>“</li>
<li>which spark-submit</li>
</ul>
<p>Copy file</p>
<ul>
<li>cp xxx.jar /usr/lib/xxx/</li>
</ul>
<p>monitor cpu and memory usage</p>
<ul>
<li>sudo install htop</li>
<li>htop</li>
<li>quit htop with press button ‘p’</li>
</ul>
<p>make directory</p>
<ul>
<li>mkdir ~/spark/src/main/scala</li>
</ul>
<p>delete file</p>
<ul>
<li>rm /home/file</li>
<li>rm -r /home/directory</li>
</ul>
<p>move file</p>
<ul>
<li>mv /test /home</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Some-basic-Linux-operation&quot;&gt;&lt;a href=&quot;#Some-basic-Linux-operation&quot; class=&quot;headerlink&quot; title=&quot;Some basic Linux operation&quot;&gt;&lt;/a&gt;Some bas
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>caffe face verification</title>
    <link href="http://yoursite.com/2017/04/25/caffe-face-verification/"/>
    <id>http://yoursite.com/2017/04/25/caffe-face-verification/</id>
    <published>2017-04-25T12:58:49.000Z</published>
    <updated>2017-05-26T17:38:41.074Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Face-verification-by-fine-tune-neural-network-on-caffe"><a href="#Face-verification-by-fine-tune-neural-network-on-caffe" class="headerlink" title="Face verification by fine-tune neural network on caffe"></a>Face verification by fine-tune neural network on caffe</h1><p>Recently I am doing face verification project on caffe. The dataset I use is LFW. Here are the methods I use.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades. It has many important applications, including surveillance, access control, image retrieval, and automatic log-on for personal computer or mobile devices. </p>
<p>The Labeled Faces in the Wild (LFW) is a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. And in this project, I used this aligned with funneling database to do face verification .</p>
<p>Alexnet and VGG net are two famous neural networks. There are mainly used in image classification, but we also can use the features that the neural work extracted to do face verification. And then use euclidean distance to produce scores for the pair image. In this project, I used both with and without fine-tuning neural network to extract the features. And I used caffe python wrapper to do this project. </p>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="without-fine-tune-Face-Verification-Process"><a href="#without-fine-tune-Face-Verification-Process" class="headerlink" title="without fine-tune Face Verification Process"></a>without fine-tune Face Verification Process</h3><p>In this project, our goal is to find the face feature, then compute the face pairs features. The process of this project is showed in here. </p>
<p><img src="../images/caffe-face-verification/face_1.png" alt="process 1"></p>
<p>Suppose our dataset have N pairs of face image, for each of face pair, we put each face pass through the neural network, then get this face pair’s feature and compute euclidean distance. And totally we can have N face pairs score. Based on these faces pairs, we can label the match pair with 1 and mismatch pair with 0. After we have these pairs scores and labels, we can plot the ROC curve for face verification.  </p>
<h3 id="fine-tune-face-verification"><a href="#fine-tune-face-verification" class="headerlink" title="fine-tune face verification"></a>fine-tune face verification</h3><p>We fine-tune neural network by creating the new neural network as Figure below showed which based on siamese network.This kind of siamese neural network usually used in verification project. </p>
<p><img src="../images/caffe-face-verification/face_2.png" alt="process 2"></p>
<p>Suppose neural network A and neural network A’ are same network structure (both Alexnet or both VGG net) without softmax layer. We change the input into face pair dataset. And use input pair and label to train the neural network. The Contrastive Loss Layer is typically used to train siamese networks.</p>
<p>After finish trained siamese networks, save the neural network A’s weights and apply it into Alexnet or VGG net. Based on the fine-tune network weight, do the do the face verification same as previous section.</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>In this project, I use caffe python wrapper.</p>
<h3 id="Alexnet-and-VGG-net-fine-tuned-model"><a href="#Alexnet-and-VGG-net-fine-tuned-model" class="headerlink" title="Alexnet and VGG net fine-tuned model"></a>Alexnet and VGG net fine-tuned model</h3><p>To build the fine-tuned neural network model, I changed the “train_val.prototxt” file. Because caffe can draw the network, so after I changed the file, I draw the neural network. The neural network structure is showed here.</p>
<p><img src="../images/caffe-face-verification/twoalexnet.jpg" alt="two alex"></p>
<p><img src="../images/caffe-face-verification/twovgg16.jpg" alt="two vgg"></p>
<h3 id="Face-features-from-Different-caffe-model"><a href="#Face-features-from-Different-caffe-model" class="headerlink" title="Face features from Different caffe model"></a>Face features from Different caffe model</h3><p>In this project, I totally used two caffe model each with two different weight. I test let some face pass this 4 neural network, and visualized its features after first convolution layer. </p>
<p>Here is one example on fine-tuned alexnet.</p>
<p><img src="../images/caffe-face-verification/alex_finetune_feature.png" alt="fine tuned alexnet feature"></p>
<h3 id="ROC-curve-results"><a href="#ROC-curve-results" class="headerlink" title="ROC curve results"></a>ROC curve results</h3><p>After we get these fine-tuned and without fine-tuned model, we can let the face pair pass these network, and extract the last fully connected layers, then compute the euclidean distance between face pairs. And this will help us get the scores for each face pair. </p>
<p>The final result for this face verification project is showed in below.<br>From the figure, we can see that the both Alexnet and Vgg net with fine-tuned weights have better performance. It prove that the neural network model after trained can increase the face verification accuracy. And we also can see that from the figure, fine-tuned vgg is better that the fine-tune alexnet, this is may caused by the vgg network have more complicate structure, it learning ability is stronger than the Alexnet. This is similar to that in image classification, vgg have better performance than alexnet. However, when both network without fine-tune, they have nearly the same performance. This may caused by that neural network was initially designed to do classification job, so they might have similar ability in face verification.</p>
<p><img src="../images/caffe-face-verification/ROC_Curve.png" alt="ROC curve"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Face-verification-by-fine-tune-neural-network-on-caffe&quot;&gt;&lt;a href=&quot;#Face-verification-by-fine-tune-neural-network-on-caffe&quot; class=&quot;hea
    
    </summary>
    
    
      <category term="-caffe" scheme="http://yoursite.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>caffe basic knowledge</title>
    <link href="http://yoursite.com/2017/04/09/caffe-basic-knowledge/"/>
    <id>http://yoursite.com/2017/04/09/caffe-basic-knowledge/</id>
    <published>2017-04-09T19:45:34.000Z</published>
    <updated>2017-04-09T19:58:29.559Z</updated>
    
    <content type="html"><![CDATA[<h1 id="some-caffe-basic-knowledge"><a href="#some-caffe-basic-knowledge" class="headerlink" title="some caffe basic knowledge"></a>some caffe basic knowledge</h1><p>For the caffe beginner, I find one article is really good for the beginner, it’s one <a href="http://manutdzou.github.io/2016/05/15/Caffe-Document.html" target="_blank" rel="external">chinese tutorial</a> but it explained caffe in detail.</p>
<h2 id="data-and-parameter"><a href="#data-and-parameter" class="headerlink" title="data and parameter"></a>data and parameter</h2><p>To run caffe, it need a model, like Alexnet. And one model make up by many layers. And every layer make up by many parameters, allthe parameter are defined in caffe.proto file. So in order to learn caffe proficiently, we myst learn how to write prototxt file.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;some-caffe-basic-knowledge&quot;&gt;&lt;a href=&quot;#some-caffe-basic-knowledge&quot; class=&quot;headerlink&quot; title=&quot;some caffe basic knowledge&quot;&gt;&lt;/a&gt;some caf
    
    </summary>
    
    
      <category term="caffe" scheme="http://yoursite.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>caffe-install-windows</title>
    <link href="http://yoursite.com/2017/04/08/caffe-install-windows/"/>
    <id>http://yoursite.com/2017/04/08/caffe-install-windows/</id>
    <published>2017-04-08T18:23:20.000Z</published>
    <updated>2017-04-08T18:50:12.304Z</updated>
    
    <content type="html"><![CDATA[<h1 id="caffe-windows-python-installed"><a href="#caffe-windows-python-installed" class="headerlink" title="caffe windows python installed"></a>caffe windows python installed</h1><p>Because of course project, I need to install caffe and use python interface.<br>I spend lots of time on searching how to install it on windows, some methods are too old, and it can not work any more. But finally after waste two nights, finally make it can run in my computer.</p>
<h2 id="windows-install-source-code"><a href="#windows-install-source-code" class="headerlink" title="windows install source code"></a>windows install source code</h2><p>There are two install way I know it can work.</p>
<ul>
<li>Use happynear github method. <a href="https://github.com/happynear/caffe-windows" target="_blank" rel="external">Github link</a></li>
<li>Use caffe official windows prebuild caffe. <a href="https://github.com/BVLC/caffe/tree/windows" target="_blank" rel="external">Github link</a></li>
</ul>
<h3 id="happynear-method"><a href="#happynear-method" class="headerlink" title="happynear method"></a>happynear method</h3><p>In his method, we must first intalled CUDA, cuDNN, Anaconda. And we only need to modify .\windows\CommonSettings.props this file. Then you can build it on VS2015.</p>
<h3 id="official-caffe"><a href="#official-caffe" class="headerlink" title="official caffe"></a>official caffe</h3><p>This is most easy way to install caffe. You only need to download the prebuild version, then it can work. </p>
<h3 id="make-python-interface-work"><a href="#make-python-interface-work" class="headerlink" title="make python interface work"></a>make python interface work</h3><p>After you have built solution with Python support, in order to use it you have to either:</p>
<ul>
<li>set PythonPath environment variable to point to <caffe_root>\Build\x64\Release\pycaffe, or</caffe_root></li>
<li>copy folder <caffe_root>\Build\x64\Release\pycaffe\caffe under <python_root>\lib\site-packages.</python_root></caffe_root></li>
</ul>
<h2 id="use-pycharm-to-run-caffe-code"><a href="#use-pycharm-to-run-caffe-code" class="headerlink" title="use pycharm to run caffe code"></a>use pycharm to run caffe code</h2><p>After installed caffe, I use the official python notebook example to test if it can work.<br>I use the <a href="https://github.com/BVLC/caffe/blob/windows/examples/00-classification.ipynb" target="_blank" rel="external">classification example</a>, and run it in pycharm. PS: the official python code is 2.7, I use python 3.5, so it might have some differences.</p>
<p>And here’s is python code!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># set up Python environment: numpy for numerical routines, and matplotlib for plotting</span></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="comment"># display plots in this notebook</span></div><div class="line"><span class="comment"># matplotlib inline</span></div><div class="line"></div><div class="line"><span class="comment"># set display defaults</span></div><div class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10</span>, <span class="number">10</span>)        <span class="comment"># large images</span></div><div class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span>  <span class="comment"># don't interpolate: show square pixels</span></div><div class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span>  <span class="comment"># use grayscale output rather than a (potentially misleading) color heatmap</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># The caffe module needs to be on the Python path;</span></div><div class="line"><span class="comment">#  we'll add it here explicitly.</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line">caffe_root = <span class="string">'F:/caffe/'</span>  <span class="comment"># this file should be run from &#123;caffe_root&#125;/examples (otherwise change this line)</span></div><div class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">'python'</span>)</div><div class="line"></div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="comment"># If you get "No module named _caffe", either you have not built pycaffe or you have the wrong path.</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">if</span> os.path.isfile(caffe_root + <span class="string">'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span>):</div><div class="line">    print(<span class="string">'CaffeNet found.'</span>)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    print(<span class="string">'Downloading pre-trained CaffeNet model...'</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#CPU</span></div><div class="line">caffe.set_mode_cpu()</div><div class="line"></div><div class="line">model_def = caffe_root + <span class="string">'models/bvlc_reference_caffenet/deploy.prototxt'</span></div><div class="line">model_weights = caffe_root + <span class="string">'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span></div><div class="line"></div><div class="line">net = caffe.Net(model_def,      <span class="comment"># defines the structure of the model</span></div><div class="line">                model_weights,  <span class="comment"># contains the trained weights</span></div><div class="line">                caffe.TEST)     <span class="comment"># use test mode (e.g., don't perform dropout)</span></div><div class="line"></div><div class="line"><span class="comment"># load the mean ImageNet image (as distributed with Caffe) for subtraction</span></div><div class="line">mu = np.load(caffe_root + <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)</div><div class="line">mu = mu.mean(<span class="number">1</span>).mean(<span class="number">1</span>)  <span class="comment"># average over pixels to obtain the mean (BGR) pixel values</span></div><div class="line">print(<span class="string">'mean-subtracted values:'</span>, list(zip(<span class="string">'BGR'</span>, mu)))</div><div class="line"></div><div class="line"><span class="comment"># create transformer for the input called 'data'</span></div><div class="line">transformer = caffe.io.Transformer(&#123;<span class="string">'data'</span>: net.blobs[<span class="string">'data'</span>].data.shape&#125;)</div><div class="line"></div><div class="line">transformer.set_transpose(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))  <span class="comment"># move image channels to outermost dimension</span></div><div class="line">transformer.set_mean(<span class="string">'data'</span>, mu)            <span class="comment"># subtract the dataset-mean value in each channel</span></div><div class="line">transformer.set_raw_scale(<span class="string">'data'</span>, <span class="number">255</span>)      <span class="comment"># rescale from [0, 1] to [0, 255]</span></div><div class="line">transformer.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))  <span class="comment"># swap channels from RGB to BGR</span></div><div class="line"></div><div class="line"><span class="comment"># set the size of the input (we can skip this if we're happy</span></div><div class="line"><span class="comment">#  with the default; we can also change it later, e.g., for different batch sizes)</span></div><div class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">50</span>,        <span class="comment"># batch size</span></div><div class="line">                          <span class="number">3</span>,         <span class="comment"># 3-channel (BGR) images</span></div><div class="line">                          <span class="number">227</span>, <span class="number">227</span>)  <span class="comment"># image size is 227x227</span></div><div class="line"></div><div class="line">image = caffe.io.load_image(caffe_root + <span class="string">'examples/images/cat.jpg'</span>)</div><div class="line">transformed_image = transformer.preprocess(<span class="string">'data'</span>, image)</div><div class="line">plt.imshow(image)</div><div class="line"></div><div class="line"><span class="comment"># copy the image data into the memory allocated for the net</span></div><div class="line">net.blobs[<span class="string">'data'</span>].data[...] = transformed_image</div><div class="line"></div><div class="line"><span class="comment">### perform classification</span></div><div class="line">output = net.forward()</div><div class="line"></div><div class="line">output_prob = output[<span class="string">'prob'</span>][<span class="number">0</span>]  <span class="comment"># the output probability vector for the first image in the batch</span></div><div class="line"></div><div class="line">print(<span class="string">'predicted class is:'</span>, output_prob.argmax())</div><div class="line"></div><div class="line"><span class="comment"># load ImageNet labels</span></div><div class="line">labels_file = caffe_root + <span class="string">'data/ilsvrc12/synset_words.txt'</span></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(labels_file):</div><div class="line">    os.system(<span class="string">"caffe/data/ilsvrc12/get_ilsvrc_aux.sh 1"</span>)</div><div class="line"></div><div class="line">labels = np.loadtxt(labels_file, str, delimiter=<span class="string">'\t'</span>)</div><div class="line"></div><div class="line">print(<span class="string">'output label:'</span>, labels[output_prob.argmax()])</div><div class="line"></div><div class="line"><span class="comment"># sort top five predictions from softmax output</span></div><div class="line">top_inds = output_prob.argsort()[::<span class="number">-1</span>][:<span class="number">5</span>]  <span class="comment"># reverse sort and take five largest items</span></div><div class="line"></div><div class="line">print(<span class="string">'probabilities and labels:'</span>,list(zip(output_prob[top_inds], labels[top_inds])))</div><div class="line"></div><div class="line"></div><div class="line">net.forward()</div><div class="line">caffe.set_device(<span class="number">0</span>)  <span class="comment"># if we have multiple GPUs, pick the first one</span></div><div class="line">caffe.set_mode_gpu()</div><div class="line">net.forward()  <span class="comment"># run once before timing to set up memory</span></div><div class="line">net.forward()</div><div class="line"></div><div class="line"><span class="comment"># for each layer, show the output shape</span></div><div class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.items():</div><div class="line">    print(layer_name + <span class="string">'\t'</span> + str(blob.data.shape))</div><div class="line"></div><div class="line"><span class="keyword">for</span> layer_name, param <span class="keyword">in</span> net.params.items():</div><div class="line">    print(layer_name + <span class="string">'\t'</span> + str(param[<span class="number">0</span>].data.shape), str(param[<span class="number">1</span>].data.shape))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span><span class="params">(data)</span>:</span></div><div class="line">    <span class="string">"""Take an array of shape (n, height, width) or (n, height, width, 3)</span></div><div class="line">       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)"""</div><div class="line"></div><div class="line">    <span class="comment"># normalize data for display</span></div><div class="line">    data = (data - data.min()) / (data.max() - data.min())</div><div class="line"></div><div class="line">    <span class="comment"># force the number of filters to be square</span></div><div class="line">    n = int(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</div><div class="line">    padding = (((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]),</div><div class="line">               (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>))                 <span class="comment"># add some space between filters</span></div><div class="line">               + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>))  <span class="comment"># don't pad the last dimension (if there is one)</span></div><div class="line">    data = np.pad(data, padding, mode=<span class="string">'constant'</span>, constant_values=<span class="number">1</span>)  <span class="comment"># pad with ones (white)</span></div><div class="line"></div><div class="line">    <span class="comment"># tile the filters into an image</span></div><div class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + tuple(range(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</div><div class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</div><div class="line"></div><div class="line">    plt.imshow(data); plt.axis(<span class="string">'off'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="comment"># the parameters are a list of [weights, biases]</span></div><div class="line">filters = net.params[<span class="string">'conv1'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</div><div class="line"></div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv1'</span>].data[<span class="number">0</span>, :<span class="number">36</span>]</div><div class="line">vis_square(feat)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'pool5'</span>].data[<span class="number">0</span>]</div><div class="line">vis_square(feat)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'fc6'</span>].data[<span class="number">0</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'prob'</span>].data[<span class="number">0</span>]</div><div class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">3</span>))</div><div class="line">plt.plot(feat.flat)</div></pre></td></tr></table></figure>
<p>If this code can run, it means I can use caffe python interface.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;caffe-windows-python-installed&quot;&gt;&lt;a href=&quot;#caffe-windows-python-installed&quot; class=&quot;headerlink&quot; title=&quot;caffe windows python installed&quot;&gt;
    
    </summary>
    
    
      <category term="caffe" scheme="http://yoursite.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>first test article</title>
    <link href="http://yoursite.com/2017/04/08/first-test-article/"/>
    <id>http://yoursite.com/2017/04/08/first-test-article/</id>
    <published>2017-04-08T04:15:30.000Z</published>
    <updated>2017-04-08T18:13:36.979Z</updated>
    
    <content type="html"><![CDATA[<h1 id="My-hexo-is-installed"><a href="#My-hexo-is-installed" class="headerlink" title="My hexo is installed"></a>My hexo is installed</h1><p>Recently, my friends told me I can use hexo and github to make my blog, which can make me learn a new things more quickly.<br>So I installed it in my computer, hope it can help me to learn it.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;My-hexo-is-installed&quot;&gt;&lt;a href=&quot;#My-hexo-is-installed&quot; class=&quot;headerlink&quot; title=&quot;My hexo is installed&quot;&gt;&lt;/a&gt;My hexo is installed&lt;/h1&gt;&lt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2017/04/07/hello-world/"/>
    <id>http://yoursite.com/2017/04/07/hello-world/</id>
    <published>2017-04-08T03:12:27.470Z</published>
    <updated>2017-04-08T03:12:27.470Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
    
    </summary>
    
    
  </entry>
  
</feed>
